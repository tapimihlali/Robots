{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import datetime as dt\n",
    "import pytz\n",
    "\n",
    "import logging\n",
    "\n",
    "from scipy.signal import savgol_filter, argrelextrema, find_peaks\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for getting price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def granular(grain='M1'):\n",
    "    \n",
    "    timeframes_mapping = {\n",
    "    'M1': [mt5.TIMEFRAME_M1, 1],\n",
    "    'M2': [mt5.TIMEFRAME_M2, 2],\n",
    "    'M3': [mt5.TIMEFRAME_M3, 3],\n",
    "    'M4': [mt5.TIMEFRAME_M4, 4],\n",
    "    'M5': [mt5.TIMEFRAME_M5, 5],\n",
    "    'M6': [mt5.TIMEFRAME_M6, 6],\n",
    "    'M10': [mt5.TIMEFRAME_M10, 10],\n",
    "    'M12': [mt5.TIMEFRAME_M12, 12],\n",
    "    'M15': [mt5.TIMEFRAME_M15, 15],\n",
    "    'M30': [mt5.TIMEFRAME_M30, 30],\n",
    "    'H1': [mt5.TIMEFRAME_H1, 60],\n",
    "    'H2': [mt5.TIMEFRAME_H2, 120],\n",
    "    'H3': [mt5.TIMEFRAME_H3, 180],\n",
    "    'H4': [mt5.TIMEFRAME_H4, 240],\n",
    "    'H6': [mt5.TIMEFRAME_H6, 360],\n",
    "    'H8': [mt5.TIMEFRAME_H8, 480],\n",
    "    'H12': [mt5.TIMEFRAME_H12, 720],\n",
    "    'D1': [mt5.TIMEFRAME_D1, 1440]    \n",
    "    }\n",
    "\n",
    "    return timeframes_mapping[grain][0]\n",
    "\n",
    "def fetch_candles(pair_name,  start_date, end_date, granularity, price):       \n",
    "    grain = granular(granularity)\n",
    "    \n",
    "    if price == 'Price':\n",
    "        price = mt5.copy_rates_range(pair_name, grain, start_date, end_date)\n",
    "        price = pd.DataFrame(price)\n",
    "        price['time'] = pd.to_datetime(price['time'], unit='s')\n",
    "        price = price.rename(columns={'time': 'date', 'tick_volume': 'volume'})\n",
    "        #price = price.set_index('date')\n",
    "\n",
    "    elif price == 'Tick':\n",
    "        price = mt5.copy_ticks_range(pair_name, start_date, end_date, mt5.COPY_TICKS_ALL)\n",
    "        price = pd.DataFrame(price)\n",
    "        price['date'] = pd.to_datetime(price['time_msc'], unit='ms')\n",
    "        price.set_index('date', inplace=True)\n",
    "        price.drop('time', axis=1, inplace=True)\n",
    "        price.drop('time_msc', axis=1, inplace=True)\n",
    "        price = price[price.columns[price.any()]]\n",
    "        #price = price.set_index('date')   \n",
    "    return price\n",
    "\n",
    "# Functions Concerned with getting Price data\n",
    "def collect_price(pair, days=5, granularity='M1',  timezone='Etc/GMT-2', price='Price'):    \n",
    "    zone = pytz.timezone(timezone)\n",
    "    now = dt.datetime.now(tz=zone)\n",
    "    dayz = days\n",
    "    start_date = now - dt.timedelta(days=dayz)\n",
    "\n",
    "    if start_date.weekday() == 6:\n",
    "        start_date -=dt.timedelta(days=2)\n",
    "\n",
    "    elif start_date.weekday() == 5:\n",
    "        start_date -=dt.timedelta(days=1)\n",
    "\n",
    "    date_from = start_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    date_to = dt.datetime(now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
    "    \n",
    "    # collect candles\n",
    "    # ap = data_api.DataApi()\n",
    "    price = fetch_candles(pair,granularity=granularity,start_date=date_from,end_date=date_to,price=price)\n",
    "    \n",
    "    if len(price) > 0:\n",
    "        final_df = price\n",
    "    elif len(price) == 0:\n",
    "        print('ERROR', pair, granularity, date_from, date_to)\n",
    "        \n",
    "    # print(f'{pair} {granularity} {final_df.iloc[0].date} {final_df.iloc[-1].date}' )\n",
    "    return final_df\n",
    "\n",
    "# Function to get the latest price\n",
    "def get_price(symbol):\n",
    "    tick = mt5.symbol_info_tick(symbol)\n",
    "    return tick.bid, tick.ask\n",
    "\n",
    "# Functions for getting market symbols and instruments\n",
    "def get_instruments_df():\n",
    "    instrument_data = []\n",
    "    ins = mt5.symbols_get()\n",
    "    for item in range(len(ins)):\n",
    "        new_ob = dict(\n",
    "            name = ins[item].name,\n",
    "            type = ins[item].path,\n",
    "            displayName = ins[item].description,\n",
    "            pipLocation = ins[item].digits,\n",
    "            marginRate = ins[item].volume_min\n",
    "        )\n",
    "        instrument_data.append(new_ob)\n",
    "    instrument_df = pd.DataFrame.from_dict(instrument_data)\n",
    "    return instrument_df\n",
    "\n",
    "def market_types(Synth_list):    \n",
    "    lis = []\n",
    "    for i in range(len(Synth_list)):\n",
    "        j = 0\n",
    "\n",
    "        lend = \"\"\n",
    "        while Synth_list[i].path[j] != \"\\\\\":\n",
    "            \n",
    "            lend = f'{lend}'+Synth_list[i].path[j]\n",
    "            j += 1\n",
    "        lis.append(lend)\n",
    "\n",
    "    condensed = list(set(lis))\n",
    "\n",
    "    secondary = []\n",
    "    for j in range(len(condensed)):\n",
    "        initial = []\n",
    "        for i in range(len(lis)):\n",
    "            if lis[i] == condensed[j]:\n",
    "                initial.append(Synth_list[i].name)\n",
    "        secondary.append(initial)\n",
    "    \n",
    "    return condensed, secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tick_data(df: pd.DataFrame,\n",
    "                    n_digits: int,\n",
    "                    timezone: str = 'Etc/GMT-2'\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    Clean and validate Forex tick data with comprehensive quality checks.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing tick data with bid/ask prices and timestamp index\n",
    "        n_digits: Number of decimal places in instrument price.\n",
    "        timezone: Timezone to localize/convert timestamps to (default: 'Etc/GMT-2')\n",
    "\n",
    "    Returns:\n",
    "        Cleaned DataFrame or None if empty after cleaning\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    df = df.copy(deep=False)  # Work on a copy to avoid modifying the original DataFrame \n",
    "    n_initial = df.shape[0] # Store initial row count for reporting\n",
    "\n",
    "    # 1. Ensure proper datetime index\n",
    "    # Use errors='coerce' to turn unparseable dates into NaT and then drop them.\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        original_index_name = df.index.name\n",
    "        df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "        nan_idx_count = df.index.isnull().sum()\n",
    "        if nan_idx_count > 0:\n",
    "            logging.info(f\"Dropped {nan_idx_count:,} rows with unparseable timestamps.\")\n",
    "            df = df[~df.index.isnull()]\n",
    "        if original_index_name:\n",
    "            df.index.name = original_index_name\n",
    "    \n",
    "    if df.empty: # Check if empty after index cleaning\n",
    "        logging.warning(\"Warning: DataFrame empty after initial index cleaning\")\n",
    "        return None\n",
    "\n",
    "    # 2. Timezone handling\n",
    "    if df.index.tz is None:\n",
    "        df = df.tz_localize(timezone)\n",
    "    elif str(df.index.tz) != timezone.upper():\n",
    "        df = df.tz_convert(timezone)\n",
    "    \n",
    "    # 3. Price validity checks\n",
    "    # Apply rounding and then filtering\n",
    "    df['bid'] = df['bid'].round(n_digits)\n",
    "    df['ask'] = df['ask'].round(n_digits)\n",
    "\n",
    "    # Validate prices\n",
    "    price_filter = (\n",
    "        (df['bid'] > 0) &\n",
    "        (df['ask'] > 0) &\n",
    "        (df['ask'] > df['bid'])\n",
    "    )\n",
    "    \n",
    "    n_before_price_filter = df.shape[0]\n",
    "    df = df[price_filter]\n",
    "    n_filtered_prices = n_before_price_filter - df.shape[0]\n",
    "    if n_filtered_prices > 0:\n",
    "        logging.info(f\"Filtered {n_filtered_prices:,} ({n_filtered_prices / n_before_price_filter:.2%}) invalid prices.\")\n",
    "\n",
    "    if df.empty: # Check if empty after price cleaning\n",
    "        logging.warning(\"Warning: DataFrame empty after price cleaning\")\n",
    "        return None\n",
    "    \n",
    "    # Dropping NA values\n",
    "    initial_rows_before_na = df.shape[0]\n",
    "    if df.isna().any().any(): # Use .any().any() to check if any NA exists in the whole DF\n",
    "        na_counts = df.isna().sum()\n",
    "        na_cols = na_counts[na_counts > 0]\n",
    "        if not na_cols.empty:\n",
    "            logging.info(f'Dropped NA values from columns: \\n{na_cols}')\n",
    "            df.dropna(inplace=True)\n",
    "\n",
    "    n_dropped_na = initial_rows_before_na - df.shape[0]\n",
    "    if n_dropped_na > 0:\n",
    "        logging.info(f\"Dropped {n_dropped_na:,} ({n_dropped_na / n_before_price_filter:.2%}) rows due to NA values.\")\n",
    "\n",
    "    if df.empty: # Check if empty after NA cleaning\n",
    "        logging.warning(\"Warning: DataFrame empty after NA cleaning\")\n",
    "        return None\n",
    "    \n",
    "    # 4. Microsecond handling\n",
    "    if not df.index.microsecond.any():\n",
    "        logging.warning(\"Warning: No timestamps with microsecond precision found\")\n",
    "    \n",
    "    # 5. Duplicate handling\n",
    "    duplicate_mask = df.index.duplicated(keep='last')\n",
    "    dup_count = duplicate_mask.sum()\n",
    "    if dup_count > 0:\n",
    "        logging.info(f\"Removed {dup_count:,} ({dup_count / n_before_price_filter:.2%}) duplicate timestamps.\")\n",
    "        df = df[~duplicate_mask]\n",
    "\n",
    "    if df.empty: # Check if empty after duplicate cleaning\n",
    "        logging.warning(\"Warning: DataFrame empty after duplicate cleaning\")\n",
    "        return None\n",
    "\n",
    "    # 6. Chronological order\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        logging.info(\"Sorting DataFrame by index to ensure chronological order.\")\n",
    "        df.sort_index(inplace=True)\n",
    "\n",
    "    # 7. Final validation and reporting\n",
    "    if df.empty:\n",
    "        logging.warning(\"Warning: DataFrame empty after all cleaning steps.\")\n",
    "        return None\n",
    "    \n",
    "    n_final = df.shape[0]\n",
    "    n_cleaned = n_initial - n_final\n",
    "    percentage_cleaned = (n_cleaned / n_initial) if n_initial > 0 else 0\n",
    "    logging.info(f\"Cleaned {n_cleaned:,} of {n_initial:,} ({percentage_cleaned:.2%}) datapoints.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def set_resampling_freq(timeframe: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts an MT5 timeframe to a pandas resampling frequency.\n",
    "\n",
    "    Args:\n",
    "        timeframe (str): MT5 timeframe (e.g., 'M1', 'M5', 'M15', 'H1', 'H4', 'D1', 'W1').\n",
    "\n",
    "    Returns:\n",
    "        str: Pandas frequency string.\n",
    "    \"\"\"\n",
    "    timeframe = timeframe.upper()\n",
    "    nums = [x for x in timeframe if x.isnumeric()]\n",
    "    if not nums:\n",
    "        raise ValueError(\"Timeframe must include numeric values (e.g., 'M1').\")\n",
    "    \n",
    "    x = int(''.join(nums))\n",
    "    if timeframe == 'W1':\n",
    "        freq = 'W-FRI'\n",
    "    elif timeframe == 'D1':\n",
    "        freq = 'B'\n",
    "    elif timeframe.startswith('H'):\n",
    "        freq = f'{x}H'\n",
    "    elif timeframe.startswith('M'):\n",
    "        freq = f'{x}min'\n",
    "    elif timeframe.startswith('S'):\n",
    "        freq = f'{x}S'\n",
    "    else:\n",
    "        raise ValueError(\"Valid timeframes include W1, D1, Hx, Mx, Sx.\")\n",
    "    \n",
    "    return freq\n",
    "\n",
    "def calculate_ticks_per_period(df: pd.DataFrame, timeframe: str = \"M1\", method: str = 'median', verbose: bool = True) -> int:\n",
    "    \"\"\"\n",
    "    Dynamically calculates the average number of ticks per given timeframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Tick data.\n",
    "        timeframe (str): MT5 timeframe.\n",
    "        method (str): 'median' or 'mean' for the calculation.\n",
    "        verbose (bool): Whether to print the result.\n",
    "\n",
    "    Returns:\n",
    "        int: Rounded average ticks per period.\n",
    "    \"\"\"\n",
    "    freq = set_resampling_freq(timeframe)\n",
    "    resampled = df.resample(freq).size()\n",
    "    fn = getattr(np, method)\n",
    "    num_ticks = fn(resampled.values)\n",
    "    num_rounded = int(np.round(num_ticks))\n",
    "    num_digits = len(str(num_rounded)) - 1\n",
    "    rounded_ticks = int(round(num_rounded, -num_digits))\n",
    "    rounded_ticks = max(1, rounded_ticks)\n",
    "    \n",
    "    if verbose:\n",
    "        t0 = df.index[0].date()\n",
    "        t1 = df.index[-1].date()\n",
    "        logging.info(f\"From {t0} to {t1}, {method} ticks per {timeframe}: {num_ticks:,} rounded to {rounded_ticks:,}\")\n",
    "    \n",
    "    return rounded_ticks\n",
    "\n",
    "def flatten_column_names(df):\n",
    "    '''\n",
    "    Joins tuples created by dataframe aggregation \n",
    "    with a list of functions into a unified name.\n",
    "    '''\n",
    "    return [\"_\".join(col).strip() for col in df.columns.values]\n",
    "\n",
    "def make_bar_type_grouper(\n",
    "        df: pd.DataFrame,\n",
    "        bar_type: str = 'tick',\n",
    "        bar_size: int = 100,\n",
    "        timeframe: str = 'M1'\n",
    ") -> tuple[pd.core.groupby.generic.DataFrameGroupBy, int]:\n",
    "    \"\"\"\n",
    "    Create a grouped object for aggregating tick data into time/tick/dollar/volume bars.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with tick data (index should be datetime for time bars).\n",
    "        bar_type: Type of bar ('time', 'tick', 'dollar', 'volume').\n",
    "        bar_size: Number of ticks/dollars/volume per bar (ignored for time bars).\n",
    "        timeframe: Timeframe for resampling (e.g., 'H1', 'D1', 'W1').\n",
    "\n",
    "    Returns:\n",
    "        - GroupBy object for aggregation\n",
    "        - Calculated bar_size (for tick/dollar/volume bars)\n",
    "    \"\"\"\n",
    "    # Create working copy (shallow is sufficient)\n",
    "    df = df.copy(deep=False)  # OPTIMIZATION: Shallow copy here only once\n",
    "    \n",
    "    # Ensure DatetimeIndex\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        try:\n",
    "            df = df.set_index('time')\n",
    "        except KeyError:\n",
    "            raise TypeError(\"Could not set 'time' as index\")\n",
    "\n",
    "    # Sort if needed\n",
    "    if not df.index.is_monotonic_increasing:\n",
    "        df = df.sort_index()\n",
    "\n",
    "    # Time bars\n",
    "    if bar_type == 'time':\n",
    "        freq = set_resampling_freq(timeframe)\n",
    "        bar_group = (df.resample(freq, closed='left', label='right') # includes data upto, but not including, the end of the period\n",
    "                    if not freq.startswith(('B', 'W')) \n",
    "                    else df.resample(freq))\n",
    "        return bar_group, 0  # bar_size not used\n",
    "\n",
    "    # Dynamic bar sizing\n",
    "    if bar_size == 0:\n",
    "        if bar_type == 'tick':\n",
    "            bar_size = calculate_ticks_per_period(df, timeframe)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{bar_type} bars require non-zero bar_size\")\n",
    "\n",
    "    # Non-time bars\n",
    "    df['time'] = df.index  # Add without copying\n",
    "    \n",
    "    if bar_type == 'tick':\n",
    "        bar_id = np.arange(len(df)) // bar_size\n",
    "    elif bar_type in ('volume', 'dollar'):\n",
    "        if 'volume' not in df.columns:\n",
    "            raise KeyError(f\"'volume' column required for {bar_type} bars\")\n",
    "        \n",
    "        # Optimized cumulative sum\n",
    "        cum_metric = (df['volume'] * df['bid'] if bar_type == 'dollar' \n",
    "                      else df['volume'])\n",
    "        cumsum = cum_metric.cumsum()\n",
    "        bar_id = (cumsum // bar_size).astype(int)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{bar_type} bars not implemented\")\n",
    "\n",
    "    return df.groupby(bar_id), bar_size\n",
    "\n",
    "def make_bars(tick_df: pd.DataFrame,\n",
    "              bar_type: str = 'tick',\n",
    "              bar_size: int = 0,\n",
    "              timeframe: str = 'M1',\n",
    "              price: str = 'midprice',\n",
    "              verbose=True):\n",
    "    '''\n",
    "    Create OHLC data by sampling ticks using timeframe or a threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tick_df: pd.DataFrame\n",
    "        tick data\n",
    "    bar_type: str\n",
    "        type of bars to create from ['tick', 'time', 'volume', 'dollar']\n",
    "    bar_size: int \n",
    "        default 0. bar_size when bar_type != 'time'\n",
    "    timeframe: str\n",
    "        MT5 timeframe (e.g., 'M5', 'H1', 'D1', 'W1').\n",
    "        Used for time bars, or for tick bars if bar_size = 0.\n",
    "    price: str\n",
    "        default midprice. If 'bid_ask', columns (bid_open, ..., bid_close), \n",
    "        (ask_open, ..., ask_close) are included.\n",
    "    verbose: bool\n",
    "        print information about the data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame with columns [open, high, low, close, median_price, tick_volume, volume]\n",
    "    '''    \n",
    "    if 'midprice' not in tick_df:\n",
    "        tick_df['midprice'] = (tick_df['bid'] + tick_df['ask']) / 2\n",
    "\n",
    "    bar_group, bar_size_ = make_bar_type_grouper(tick_df, bar_type, bar_size, timeframe)\n",
    "    ohlc_df = bar_group['midprice'].ohlc().astype('float64')\n",
    "    ohlc_df['tick_volume'] = bar_group['bid'].count() if bar_type != 'tick' else bar_size_\n",
    "    \n",
    "    if price == 'bid_ask':\n",
    "        # Aggregate OHLC data for every bar_size rows\n",
    "        bid_ask_df = bar_group.agg({k: 'ohlc' for k in ('bid', 'ask')})\n",
    "        # Flatten MultiIndex columns\n",
    "        col_names = flatten_column_names(bid_ask_df)\n",
    "        bid_ask_df.columns = col_names\n",
    "        ohlc_df = ohlc_df.join(bid_ask_df)\n",
    "\n",
    "    if 'volume' in tick_df:\n",
    "        ohlc_df['volume'] = bar_group['volume'].sum()\n",
    "\n",
    "    if bar_type == 'time':\n",
    "        ohlc_df.ffill(inplace=True)\n",
    "    else:\n",
    "        end_time =  bar_group['time'].last()\n",
    "        ohlc_df.index = end_time + pd.Timedelta(microseconds=1) # ensure end time is after event\n",
    "\t    # ohlc_df.drop('time', axis=1, inplace=True) # Remove 'time' column\n",
    "\n",
    "\n",
    "        # drop last bar due to insufficient ticks\n",
    "        if len(tick_df) % bar_size_ > 0: \n",
    "            ohlc_df = ohlc_df.iloc[:-1]\n",
    "\n",
    "    if verbose:\n",
    "        if bar_type != 'time':\n",
    "            tm = f'{bar_size_:,}'\n",
    "            if bar_type == 'tick' and bar_size == 0:\n",
    "                tm = f'{timeframe} - {bar_size_:,} ticks'\n",
    "            timeframe = tm\n",
    "        print(f'\\nTick data - {tick_df.shape[0]:,} rows')\n",
    "        print(f'{bar_type}_bar {timeframe}')\n",
    "        ohlc_df.info()\n",
    "    \n",
    "    # Remove timezone info from DatetimeIndex\n",
    "    try:\n",
    "\t    ohlc_df = ohlc_df.tz_convert(None)\n",
    "     \n",
    "    except:\n",
    "\t    pass\n",
    "    \n",
    "    return ohlc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Trade Management and entering trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place a trade\n",
    "def place_trade(symbol, lot, direction, stop_loss_pips, take_profit_pips):\n",
    "    price = get_price(symbol)\n",
    "    deviation = 10\n",
    "    trade_type = mt5.ORDER_TYPE_BUY if direction == \"buy\" else mt5.ORDER_TYPE_SELL\n",
    "    # sl = price[0] - stop_loss_pips * 0.0001 if direction == \"buy\" else price[0] + stop_loss_pips * 0.0001\n",
    "    # tp = price[0] + take_profit_pips * 0.0001 if direction == \"buy\" else price[0] - take_profit_pips * 0.0001\n",
    "    \n",
    "    sl = stop_loss_pips if direction == \"buy\" else stop_loss_pips\n",
    "    tp = take_profit_pips if direction == \"buy\" else take_profit_pips\n",
    "    \n",
    "    request = {\n",
    "        \"action\": mt5.TRADE_ACTION_DEAL,\n",
    "        \"symbol\": symbol,\n",
    "        \"volume\": lot,\n",
    "        \"type\": trade_type,\n",
    "        \"price\": price[1] if direction == \"buy\" else price[0],\n",
    "        \"sl\": sl,\n",
    "        \"tp\": tp,\n",
    "        \"deviation\": deviation,\n",
    "        \"magic\": 100001,\n",
    "        \"comment\": \"Martingale trade\",\n",
    "        \"type_time\": mt5.ORDER_TIME_GTC\n",
    "    }\n",
    "    return mt5.order_send(request)\n",
    "\n",
    "# Function to check last trade outcome\n",
    "def check_last_trade():\n",
    "    history = mt5.history_deals_get()\n",
    "    if history:\n",
    "        last_trade = list(history)[-1]\n",
    "        return last_trade.profit < 0  # Return True if last trade was a loss\n",
    "    return False\n",
    "\n",
    "# Function to check daily profit\n",
    "def get_daily_profit():\n",
    "    today = datetime.datetime.now().date()\n",
    "    deals = mt5.history_deals_get(datetime.datetime(today.year, today.month, today.day), datetime.datetime.now())\n",
    "    return sum(deal.profit for deal in deals if deal.profit is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import indicators as indie\n",
    "import Set_functions as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candles_frame(Symbol, entry_strat='MA_cross', short_days=6, long_days=6, short_tf='M1', mid_tf='M15', long_tf='M30', high_tf='M30', X_tf='H1'):\n",
    "\n",
    "    # stop_level = SF.stop_levels(Symbol, Synth_list)[0]\n",
    "    # lot_size_min = SF.stop_levels(Symbol, Synth_list)[1]\n",
    "    # lot_size_max = SF.stop_levels(Symbol, Synth_list)[2]\n",
    "\n",
    "    df = SF.get_tick(pair=Symbol, days=short_days, granularity=short_tf)\n",
    "    # df_01 = df.copy()\n",
    "    df_02 = SF.get_tick(pair=Symbol, days=short_days, granularity=mid_tf)\n",
    "    df_03 = SF.get_tick(pair=Symbol, days=long_days, granularity=long_tf)\n",
    "    df_04 = SF.get_tick(pair=Symbol, days=long_days, granularity=high_tf)\n",
    "    df_05 = SF.get_tick(pair=Symbol, days=10, granularity=X_tf)\n",
    "    \n",
    "    df_01a = SF.get_tick(pair=Symbol, days=short_days, granularity=\"M5\")\n",
    "    \n",
    "    df['ATR'] = indie.atr(df, 7)\n",
    "\n",
    "    data = df.rename(columns={'close': 'Close', 'low': 'Low', 'high': 'High', 'date': 'Date', 'open' : 'Open'})\n",
    "    \n",
    "        # Assume df_m15 has datetime index and OHLC data\n",
    "    df_m5 = indie.compute_cci(df_02.rename(columns={'close': 'Close', 'low': 'Low', 'high': 'High', 'date': 'Date', 'open' : 'Open'}), n=40)\n",
    "    # df_m5 = df_m5.dropna(subset=['cci_40'])\n",
    "\n",
    "    df_m15 = indie.compute_cci(df_03.rename(columns={'close': 'Close', 'low': 'Low', 'high': 'High', 'date': 'Date', 'open' : 'Open'}), n=40)\n",
    "    # df_m15 = df_m15.dropna(subset=['cci_40'])\n",
    "\n",
    "    df_h1 = indie.compute_cci(df_05.rename(columns={'close': 'Close', 'low': 'Low', 'high': 'High', 'date': 'Date', 'open' : 'Open'}), n=40)\n",
    "    # df_h1 = df_h1.dropna(subset=['cci_40'])\n",
    "\n",
    "    df['h1_cross'] = pd.DataFrame(SF.track_cci_cross_moves_with_time(df_h1)).set_index(0).reindex(df.index, method='ffill')\n",
    "    df['m15_cross'] = pd.DataFrame(SF.track_cci_cross_moves_with_time(df_m15)).set_index(0).reindex(df.index, method='ffill')\n",
    "    df['m5_cross'] = pd.DataFrame(SF.track_cci_cross_moves_with_time(df_m5)).set_index(0).reindex(df.index, method='ffill')\n",
    "    \n",
    "    # Create a preliminary signal for Stochastic Entries\n",
    "    if entry_strat == \"Simple\":\n",
    "        df[\"Signal\"] = SF.create_signals(data, algo=SF.simple_signal)\n",
    "\n",
    "    elif entry_strat == \"ICT\":   \n",
    "        df[\"Signal\"] = SF.create_signals(df, algo=SF.ICT_signal)\n",
    "\n",
    "    elif entry_strat == \"Mharris\":   \n",
    "        df[\"Signal\"] = SF.create_signals(df, algo=SF.Mharris_signal)\n",
    "\n",
    "    elif entry_strat == \"Stoch\":\n",
    "        full_stoch = indie.stoch(df, 50)\n",
    "        df['D'] = full_stoch.slow_d\n",
    "        df['K'] = full_stoch.slow_k\n",
    "        df[\"Signal\"] = SF.create_signals(df, algo=SF.stoch_signal)\n",
    "        \n",
    "    elif entry_strat == \"MA_cross\":\n",
    "        MA1 = indie.rolling_mean(df.close, 2)\n",
    "        MA5 = indie.rolling_mean(df.close, 6)\n",
    "        df['crause'] = SF.crossover_lines(df, MA1, MA5)['positions']\n",
    "        df[\"Signal\"] = SF.create_signals(df, algo=SF.cross_signal)\n",
    "        \n",
    "    elif entry_strat == \"Peaks_Valleys\":\n",
    "        df_hl = df_02.rename(columns={'close': 'Close', 'low': 'Low', 'high': 'High', 'date': 'Date', 'open' : 'Open'})\n",
    "        df_hl = df_hl.set_index('Date')\n",
    "        highs_lows = SF.peak_vall(df_hl)\n",
    "        df[\"Highs_lows\"] = highs_lows['Signal'].reindex(df.index)\n",
    "        df[\"Signal\"] = SF.create_signals(df, algo=SF.p_v_signal)\n",
    "\n",
    "    # df = df.set_index('date')\n",
    "\n",
    "    # Creating Z Wave with it's cyclic directional arrows\n",
    "    line_04, line_0_dated4, line_14, line_1_dated4 = SF.smooth_frame_lines(df_04, line='MACD')\n",
    "    k_wave = line_1_dated4.line0\n",
    "    trend_d_ind4, trend_d_loc_main4, trend_u_ind4, trend_u_loc_main4 = SF.waveler_01(k_wave)\n",
    "    \n",
    "    circle1c = pd.DataFrame()\n",
    "    circle2c = pd.DataFrame()\n",
    "\n",
    "    circle1c['values'] = trend_d_loc_main4\n",
    "    circle1c['direction'] = 1\n",
    "    circle2c['values'] = trend_u_loc_main4\n",
    "    circle2c['direction'] = 2\n",
    "\n",
    "    circlec = pd.concat([circle1c, circle2c]).sort_index()\n",
    "    circc = circlec\n",
    "\n",
    "    # Creating Z Wave with it's cyclic directional arrows\n",
    "    line_03, line_0_dated3, line_13, line_1_dated3 = SF.smooth_frame_lines(df_03, line='MACD')\n",
    "    z_wave = line_1_dated3.line0\n",
    "    trend_d_ind3, trend_d_loc_main3, trend_u_ind3, trend_u_loc_main3 = SF.waveler_01(z_wave)\n",
    "\n",
    "    circle1 = pd.DataFrame()\n",
    "    circle2 = pd.DataFrame()\n",
    "\n",
    "    circle1['values'] = trend_d_loc_main3\n",
    "    circle1['direction'] = 1\n",
    "    circle2['values'] = trend_u_loc_main3\n",
    "    circle2['direction'] = 2\n",
    "\n",
    "    circle = pd.concat([circle1, circle2]).sort_index()\n",
    "    circ = circle\n",
    "\n",
    "    line_02, line_0_dated2, line_12, line_1_dated2 = SF.smooth_frame_lines(df_02, line='MACD')\n",
    "    y_wave = line_1_dated2.line0\n",
    "    trend_d_ind2, trend_d_loc_main2, trend_u_ind2, trend_u_loc_main2 = SF.waveler_01(y_wave)\n",
    "\n",
    "    circle1a = pd.DataFrame()\n",
    "    circle2a = pd.DataFrame()\n",
    "\n",
    "    circle1a['values'] = trend_d_loc_main2\n",
    "    circle1a['direction'] = 1\n",
    "    circle2a['values'] = trend_u_loc_main2\n",
    "    circle2a['direction'] = 2\n",
    "\n",
    "    circlea = pd.concat([circle1a, circle2a]).sort_index()\n",
    "    circa = circlea\n",
    "\n",
    "    # df_03 = df_03.set_index('date')\n",
    "    peaks, valleys, stretch_filtered, Divergence, Div_date, MA_13, MA_34, norm_stretch_df, Points = SF.divergence_norm(df_03)\n",
    "    # peaks, valleys, stretch_filtered, Divergence, Div_date, MA_13, MA_34, norm_stretch_df, Points = SF.divergence_norm_realtime(df_03)\n",
    "    \n",
    "    # df_02 = df_02.set_index('date')\n",
    "    cCCi = indie.compute_cci(df_02.rename(columns={'close': 'Close', 'low': 'Low', 'high': 'High', 'date': 'Date', 'open' : 'Open'}), n=25)\n",
    "\n",
    "    # df['Z'] = cCCi.reindex(df.index, method='ffill')#SF.calculate_z_score(df_01['close'].reindex(df.index, method='ffill'))#\n",
    "    df['cci_02'] = cCCi.reindex(df.index, method='ffill')\n",
    "    \n",
    "    cci_03 = indie.compute_cci(df_04.rename(columns={'close': 'Close', 'low': 'Low', 'high': 'High', 'date': 'Date', 'open' : 'Open'}), n=100)\n",
    "    \n",
    "    cci_04 = indie.compute_cci(df_05.rename(columns={'close': 'Close', 'low': 'Low', 'high': 'High', 'date': 'Date', 'open' : 'Open'}), n=100)\n",
    "    \n",
    "    df['cci_03'] = cci_03.reindex(df.index).interpolate()\n",
    "    \n",
    "    df['cci_M30'] = SF.mark_bias(df_04, cci_col=cci_03, upper=100, lower=-100)['bias'].reindex(df.index, method='ffill')\n",
    "    \n",
    "    df['cci_H4'] = SF.mark_bias(df_05, cci_col=cci_04, upper=100, lower=-100)['bias'].reindex(df.index, method='ffill')\n",
    "    \n",
    "    # Lines = abs(norm_stretch_df['norm_stretch'])\n",
    "    # Line_AB = norm_stretch_df['stretch_filtered']\n",
    "    \n",
    "    Deviate = SF.dev_indicator(df_03, df_03)\n",
    "    \n",
    "    # Points_01 = SF.double_point(Points)\n",
    "    \n",
    "    # df['Points_01'] = Points_01['Divergence_01'].ffill().reindex(df.index, method='ffill')\n",
    "    \n",
    "    # df_05 = df_05.set_index('date')\n",
    "    peaks_01, valleys_01, stretch_filtered_01, Divergence_01, Div_date_01, MA_13_01, MA_34_01, norm_stretch_df_01, Points_01 = SF.divergence_norm(df_05)\n",
    "    \n",
    "    # df['Sides'] = norm_stretch_df_01['stretch_filtered'].reindex(df.index, method='ffill')\n",
    "    \n",
    "    # df['Lines'] = norm_stretch_df_01['stretch_filtered'].ffill().diff().reindex(df.index, method='ffill')\n",
    "    \n",
    "    df['Z'] = norm_stretch_df['norm_stretch'].reindex(df.index, method='ffill')#SF.calculate_z_score(df_01['close'].reindex(df.index, method='ffill'))##cCCi#\n",
    "    df['Confirm'] = norm_stretch_df['stretch_filtered'].ffill().diff().reindex(df.index, method='ffill')\n",
    "    \n",
    "    centred = np.mean(norm_stretch_df['norm_stretch'])\n",
    "    up_c = centred + np.std(norm_stretch_df['norm_stretch'])\n",
    "    down_c = centred - np.std(norm_stretch_df['norm_stretch'])\n",
    "    \n",
    "\n",
    "    # Joining the Circle to the DataFrames\n",
    "    df['HTF_cyc'] = circ['direction'].reindex(df.index, method='ffill')\n",
    "    df['MTF_cyc'] = circa['direction'].reindex(df.index, method='ffill')\n",
    "    \n",
    "    df['deviate'] = Deviate[0].reindex(df.index, method='ffill')\n",
    "\n",
    "    # Creating the signals for the trades\n",
    "    Final_signal = []\n",
    "    for i in range(len(df)):\n",
    "        ind = i-1\n",
    "        # if (df['Points_01'].iloc[ind] == 'Down') & (df['HTF_cyc'].iloc[ind] == 2) :#& (df['MTF_cyc'].iloc[ind] == 2):\n",
    "        #     Final_signal.append(1)\n",
    "            \n",
    "        # elif (df['Points_01'].iloc[ind] == 'Up') & (df['HTF_cyc'].iloc[ind] == 1) :#& (df['MTF_cyc'].iloc[ind] == 1):\n",
    "        #     Final_signal.append(2)\n",
    "            \n",
    "        # else:\n",
    "        #     Final_signal.append(0)\n",
    "            \n",
    "        # if (df['Signal'].iloc[ind-1] == 1) & (df['Sides'].iloc[ind] < centred) & (df['Sides'].iloc[ind] < up_c) & (df['HTF_cyc'].iloc[ind] == 2) & (df['MTF_cyc'].iloc[ind] == 2): #(df['Lines'].iloc[ind] <= 0)\n",
    "        #     Final_signal.append(1)\n",
    "            \n",
    "        # elif (df['Signal'].iloc[ind-1] == 2) & (df['Sides'].iloc[ind] > centred) & (df['Sides'].iloc[ind] > down_c) & (df['HTF_cyc'].iloc[ind] == 1) & (df['MTF_cyc'].iloc[ind] == 1): #(df['Lines'].iloc[ind] >= 0)\n",
    "        #     Final_signal.append(2)\n",
    "        \n",
    "        # if (df['Signal'].iloc[ind-1] == 1) & (df['m15_cross'].iloc[ind] == 'down') & (df['m5_cross'].iloc[ind] == 'down') & (df['MTF_cyc'].iloc[ind] == 2) & (df['deviate'].iloc[ind] == 1): #& (df['HTF_cyc'].iloc[ind] == 1) & (df['h1_cross'].iloc[ind] == 'down')(df['Lines'].iloc[ind] <= 0) (df['Sides'].iloc[ind] < centred) & (df['Sides'].iloc[ind] < up_c)\n",
    "        #     Final_signal.append(2)\n",
    "            \n",
    "        # elif (df['Signal'].iloc[ind-1] == 2)& (df['m15_cross'].iloc[ind] == 'up') & (df['m5_cross'].iloc[ind] == 'up') & (df['MTF_cyc'].iloc[ind] == 1) & (df['deviate'].iloc[ind] == 2): #& (df['HTF_cyc'].iloc[ind] == 2) & (df['h1_cross'].iloc[ind] == 'up') (df['Lines'].iloc[ind] >= 0) (df['Sides'].iloc[ind] > centred) & (df['Sides'].iloc[ind] > down_c)\n",
    "        #     Final_signal.append(1)\n",
    "        if (df['Signal'].iloc[ind-1] == 1) & (df['cci_02'].iloc[ind] < -100) & (df['MTF_cyc'].iloc[ind] == 1) & (df['cci_M30'].iloc[ind] == 'up') & (df['cci_H4'].iloc[ind] == 'up') : #  & & ((df['open_zone'].iloc[ind]=='upper') or (df['cci_03'].iloc[ind] >= 100))(df['deviate'].iloc[ind] == 2) & (df['open_range'].iloc[ind] >= open_mean*0.35 + open_mean)& (df['LTF_cyc'].iloc[ind] == 1) & (df['m5_cross'].iloc[ind] == 'up')& (df['m15_cross'].iloc[ind] == 'down')    & (df['Z'].iloc[ind] >=0) & (df['HTF_cyc'].iloc[ind] == 2)& (df['h1_cross'].iloc[ind] == 'down')(df['Lines'].iloc[ind] <= 0) (df['Sides'].iloc[ind] < centred) & (df['Sides'].iloc[ind] < up_c)\n",
    "            Final_signal.append(2)\n",
    "            \n",
    "        elif (df['Signal'].iloc[ind-1] == 2)& (df['cci_02'].iloc[ind] > 100) & (df['MTF_cyc'].iloc[ind] == 2) & (df['cci_M30'].iloc[ind] == 'down')  & (df['cci_H4'].iloc[ind] == 'down'): #& ((df['open_zone'].iloc[ind]=='lower') or (df['cci_03'].iloc[ind] <= -100)) & (df['deviate'].iloc[ind] == 1)  & (df['open_range'].iloc[ind] >= open_mean*0.35 + open_mean) & (df['m5_cross'].iloc[ind] == 'down')& (df['m15_cross'].iloc[ind] == 'up')  & (df['Z'].iloc[ind] <=0) & (df['HTF_cyc'].iloc[ind] == 1) & (df['h1_cross'].iloc[ind] == 'up') (df['Lines'].iloc[ind] >= 0) (df['Sides'].iloc[ind] > centred) & (df['Sides'].iloc[ind] > down_c)\n",
    "            Final_signal.append(1)    \n",
    "        \n",
    "        else:\n",
    "            Final_signal.append(0)\n",
    "\n",
    "    df['Final_signal'] = Final_signal\n",
    "    \n",
    "    return df, y_wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Logins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login details\n",
    "User = 5228413#20765584#\n",
    "Pass = \"$kyrock3tinG\"\n",
    "Server = \"Deriv-Demo\"\n",
    "path_0 = \"C:\\\\Program Files\\\\MetaTrader 5\\\\terminal64.exe\"\n",
    "\n",
    "# Initialize connection to MT5\n",
    "if not mt5.initialize(path=path_0, login=User, server=Server,password=Pass):\n",
    "    print(\"Failed to initialize MT5\")\n",
    "    mt5.shutdown()\n",
    "    \n",
    "# if not mt5.login(login=User, server=Server,password=Pass):\n",
    "#     print(\"login() failed, error code =\", mt5.last_error())\n",
    "#     quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Markets and Symbols from the broker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stock Indices',\n",
       " 'Tactical Indices',\n",
       " 'Skewed Step',\n",
       " 'Equities',\n",
       " 'Forex Major',\n",
       " 'Crash Boom Indices',\n",
       " 'Step Indices',\n",
       " 'Trek Indices',\n",
       " 'Range Break',\n",
       " 'Energies',\n",
       " 'Drift Switching Indices',\n",
       " 'Crypto',\n",
       " 'Stable Spreads',\n",
       " 'Volatility Indices',\n",
       " 'Forex Exotic',\n",
       " 'Basket Indices',\n",
       " 'Forex Minor',\n",
       " 'Multi Step Indices',\n",
       " 'Conversions',\n",
       " 'Volatility Switch Indices',\n",
       " 'ETFs',\n",
       " 'DEX Indices',\n",
       " 'Derived Indices',\n",
       " 'Soft Commodities',\n",
       " 'Forex Micro',\n",
       " 'Jump Indices',\n",
       " 'Metals',\n",
       " 'Hybrid Indices']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Options_1 =  market_types(mt5.symbols_get())[0]         # Type of markets available with Broker\n",
    "Options_2 =  market_types(mt5.symbols_get())[1]         # Currenc pair to be selected\n",
    "        \n",
    "Options_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUDJPY',\n",
       " 'AUDUSD',\n",
       " 'EURAUD',\n",
       " 'EURCAD',\n",
       " 'EURCHF',\n",
       " 'EURGBP',\n",
       " 'EURJPY',\n",
       " 'EURUSD',\n",
       " 'GBPJPY',\n",
       " 'GBPUSD',\n",
       " 'USDCAD',\n",
       " 'USDCHF',\n",
       " 'USDJPY',\n",
       " 'GBPAUD']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From the \"Options_1\" list above, input the Market instruments you want to look at and get a print of the symbols you'll be focusing on\n",
    "for i in range(len(Options_1)):\n",
    "    if Options_1[i] == \"Forex Major\":##\"Volatility Indices\":'Cent':#'Forex Minor':#'DEX Indices':#\"Crypto\":#\"Metals\":#'Equities':#'ETFs':#\n",
    "        ind = i\n",
    "        break\n",
    "\n",
    "# Define a global variable to store the selected index\n",
    "Market_value = Options_1[ind]\n",
    "Market_ind = Options_1.index(Market_value)\n",
    "\n",
    "All_symbols = Options_2[Market_ind]\n",
    "\n",
    "All_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All_symbols.pop(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AUDJPY',\n",
       " 'AUDUSD',\n",
       " 'EURAUD',\n",
       " 'EURCAD',\n",
       " 'EURCHF',\n",
       " 'EURGBP',\n",
       " 'EURJPY',\n",
       " 'EURUSD',\n",
       " 'GBPJPY',\n",
       " 'GBPUSD',\n",
       " 'USDCAD',\n",
       " 'USDCHF',\n",
       " 'USDJPY',\n",
       " 'GBPAUD']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplier_list = np.ones(len(All_symbols))*0.01#[0.0015, 0.005, 0.009, 0.013, 0.02, 0.0015, 0.0035, 0.004, 0.008, 0.01, 0.01, 0.02, 0.013, 0.02, 0.028]\n",
    "# multiplier_list.pop(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiplier_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     lot_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\u001b[38;5;66;03m#lot_size_min\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Getting the Analysed Price for each symbol\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m get, y_wave \u001b[38;5;241m=\u001b[39m get_candles_frame(Symbol\u001b[38;5;241m=\u001b[39msymbol, entry_strat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSimple\u001b[39m\u001b[38;5;124m'\u001b[39m, short_days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, long_days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, short_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM1\u001b[39m\u001b[38;5;124m'\u001b[39m, mid_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM15\u001b[39m\u001b[38;5;124m'\u001b[39m, long_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM30\u001b[39m\u001b[38;5;124m'\u001b[39m, high_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM30\u001b[39m\u001b[38;5;124m'\u001b[39m, X_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m centre \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(get[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     34\u001b[0m up_c \u001b[38;5;241m=\u001b[39m centre \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(get[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[10], line 186\u001b[0m, in \u001b[0;36mget_candles_frame\u001b[1;34m(Symbol, entry_strat, short_days, long_days, short_tf, mid_tf, long_tf, high_tf, X_tf)\u001b[0m\n\u001b[0;32m    165\u001b[0m ind \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# if (df['Points_01'].iloc[ind] == 'Down') & (df['HTF_cyc'].iloc[ind] == 2) :#& (df['MTF_cyc'].iloc[ind] == 2):\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m#     Final_signal.append(1)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# elif (df['Signal'].iloc[ind-1] == 2)& (df['m15_cross'].iloc[ind] == 'up') & (df['m5_cross'].iloc[ind] == 'up') & (df['MTF_cyc'].iloc[ind] == 1) & (df['deviate'].iloc[ind] == 2): #& (df['HTF_cyc'].iloc[ind] == 2) & (df['h1_cross'].iloc[ind] == 'up') (df['Lines'].iloc[ind] >= 0) (df['Sides'].iloc[ind] > centred) & (df['Sides'].iloc[ind] > down_c)\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m#     Final_signal.append(1)\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSignal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcci_02\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMTF_cyc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcci_M30\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcci_H4\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mup\u001b[39m\u001b[38;5;124m'\u001b[39m) : \u001b[38;5;66;03m#  & & ((df['open_zone'].iloc[ind]=='upper') or (df['cci_03'].iloc[ind] >= 100))(df['deviate'].iloc[ind] == 2) & (df['open_range'].iloc[ind] >= open_mean*0.35 + open_mean)& (df['LTF_cyc'].iloc[ind] == 1) & (df['m5_cross'].iloc[ind] == 'up')& (df['m15_cross'].iloc[ind] == 'down')    & (df['Z'].iloc[ind] >=0) & (df['HTF_cyc'].iloc[ind] == 2)& (df['h1_cross'].iloc[ind] == 'down')(df['Lines'].iloc[ind] <= 0) (df['Sides'].iloc[ind] < centred) & (df['Sides'].iloc[ind] < up_c)\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     Final_signal\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSignal\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcci_02\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMTF_cyc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcci_M30\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdown\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcci_H4\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[ind] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdown\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;66;03m#& ((df['open_zone'].iloc[ind]=='lower') or (df['cci_03'].iloc[ind] <= -100)) & (df['deviate'].iloc[ind] == 1)  & (df['open_range'].iloc[ind] >= open_mean*0.35 + open_mean) & (df['m5_cross'].iloc[ind] == 'down')& (df['m15_cross'].iloc[ind] == 'up')  & (df['Z'].iloc[ind] <=0) & (df['HTF_cyc'].iloc[ind] == 1) & (df['h1_cross'].iloc[ind] == 'up') (df['Lines'].iloc[ind] >= 0) (df['Sides'].iloc[ind] > centred) & (df['Sides'].iloc[ind] > down_c)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vusi\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Vusi\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1737\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m   1735\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n\u001b[1;32m-> 1737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\Vusi\\anaconda3\\Lib\\site-packages\\pandas\\core\\common.py:125\u001b[0m, in \u001b[0;36mis_bool_indexer\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mis_bool_indexer\u001b[39m(key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    Check whether `key` is a valid boolean indexer.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m        and convert to an ndarray.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    126\u001b[0m         key, (ABCSeries, np\u001b[38;5;241m.\u001b[39mndarray, ABCIndex, ABCExtensionArray)\n\u001b[0;32m    127\u001b[0m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, ABCMultiIndex):\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    129\u001b[0m             key_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n",
      "File \u001b[1;32mc:\\Users\\Vusi\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py:44\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._instancecheck\u001b[1;34m(cls, inst)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_instancecheck\u001b[39m(\u001b[38;5;28mcls\u001b[39m, inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _check(inst) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inst, \u001b[38;5;28mtype\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Vusi\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\generic.py:38\u001b[0m, in \u001b[0;36mcreate_pandas_abc_type.<locals>._check\u001b[1;34m(inst)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_check\u001b[39m(inst) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(inst, attr, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_typ\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m comp\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "martingale_multiplier = 2.0\n",
    "sl_multiplier = 100\n",
    "tp_multiplier = 100\n",
    "daily_profit_target = 1000.0  # Set your daily profit target\n",
    "\n",
    "\n",
    "\n",
    "# Martingale trading loop\n",
    "while True:\n",
    "    for i in range(len(All_symbols)):\n",
    "        \n",
    "        symbol = All_symbols[i]\n",
    "        \n",
    "        # Setting up the lot size for each symbol\n",
    "        stop_level, lot_size_min, lot_size_max = SF.stop_levels(Symbol=symbol, Synth_list=mt5.symbols_get())\n",
    "        lot_size = 0.05#lot_size_min\n",
    "        max_lot = lot_size_max\n",
    "        \n",
    "        # # Creating a Martingale system\n",
    "        daily_profit = get_daily_profit()\n",
    "        # if daily_profit >= daily_profit_target:\n",
    "        #     print(f\"Target reached! Daily Profit: ${daily_profit:.2f}\")\n",
    "        #     break  # Stop trading for the day\n",
    "        \n",
    "        if check_last_trade():\n",
    "            lot_size = min(lot_size * martingale_multiplier, max_lot)\n",
    "        else:\n",
    "            lot_size = 0.05#lot_size_min\n",
    "        \n",
    "        # Getting the Analysed Price for each symbol\n",
    "        get, y_wave = get_candles_frame(Symbol=symbol, entry_strat='Simple', short_days=6, long_days=6, short_tf='M1', mid_tf='M15', long_tf='M30', high_tf='M30', X_tf='H1')\n",
    "        \n",
    "        centre = np.mean(get['Z'])\n",
    "        up_c = centre + np.std(get['Z'])\n",
    "        # down_c = centre - np.std(get['norm_stretch'])\n",
    "\n",
    "        # SF.detect_zscore_exit_signals(df, level=up_c)\n",
    "        \n",
    "        get = SF.detect_zscore_exit_signals(df=get, level=up_c)\n",
    "        \n",
    "        peaks, _ = find_peaks(y_wave, distance=15, prominence=0.2)\n",
    "        valleys, _ = find_peaks(-y_wave, distance=15, prominence=0.2)\n",
    "        \n",
    "        # Setting up the stop loss and take profits\n",
    "        atr = get.ATR.iloc[-1]\n",
    "        \n",
    "        if get['Final_signal'].iloc[-1] == 2:\n",
    "            price = mt5.symbol_info_tick(symbol).ask\n",
    "            stop_loss_pips = price - (atr * sl_multiplier)\n",
    "            take_profit_pips = price + (atr * tp_multiplier)\n",
    "            \n",
    "            bet = place_trade(symbol, lot_size, \"buy\", stop_loss_pips, take_profit_pips)\n",
    "            \n",
    "            if bet.retcode == 10009:\n",
    "                print(f\"For {symbol}:\")\n",
    "                print(f\"Placed a buy trade with {lot_size} lots. Current Daily Profit: ${daily_profit:.2f}\") \n",
    "            \n",
    "            elif bet.retcode != 10009:\n",
    "                print(f\"For {symbol}:\")\n",
    "                print(f\"Error buy: {bet.retcode}, no trade opened!\")          \n",
    "            \n",
    "        elif get['Final_signal'].iloc[-1] == 1:\n",
    "            price = mt5.symbol_info_tick(symbol).bid\n",
    "            stop_loss_pips = price + (atr * sl_multiplier)\n",
    "            take_profit_pips = price - (atr * tp_multiplier)\n",
    "            \n",
    "            bet = place_trade(symbol, lot_size, \"sell\", stop_loss_pips, take_profit_pips)  # Example strategy: always buy\n",
    "            \n",
    "            if bet.retcode == 10009:\n",
    "                print(f\"For {symbol}:\")\n",
    "                print(f\"Placed a sell trade with {lot_size} lots. Current Daily Profit: ${daily_profit:.2f}\")\n",
    "            \n",
    "            elif bet.retcode != 10009:\n",
    "                print(f\"For {symbol}:\")\n",
    "                print(f\"Error sell: {bet.retcode}, no trade opened!\")\n",
    "        \n",
    "        # Check profit level, so as to close in profit\n",
    "        positions = mt5.positions_get()\n",
    "        \n",
    "        if get['z_exit_signal'].iloc[-1] == 1 or get['z_exit_signal'].iloc[-2] == 1:\n",
    "            if len(positions) > 0:\n",
    "                for j in range(len(positions)):\n",
    "                    if positions[j].symbol == symbol:                   \n",
    "                        # Order type is a buy\n",
    "                        if positions[j].type == 0:\n",
    "                            # SF.close_all_trades(symbol, positions)\n",
    "                            SF.close_all_trades_01(symbol, positions, type=0)\n",
    "                            print(f'Symbol {symbol} closed at Profit')\n",
    "                            \n",
    "        elif get['z_exit_signal'].iloc[-1] == -1 or get['z_exit_signal'].iloc[-2] == -1:\n",
    "            if len(positions) > 0:\n",
    "                for j in range(len(positions)):\n",
    "                    if positions[j].symbol == symbol:                   \n",
    "                        # Order type is a sell    \n",
    "                        if positions[j].type == 1:\n",
    "                            # SF.close_all_trades(symbol, positions)\n",
    "                            SF.close_all_trades_01(symbol, positions, type=1)\n",
    "                            print(f'Symbol {symbol} closed at Profit')\n",
    "        \n",
    "        elif (get['cci_M30'].iloc[-1] == 'down') and (get['cci_H4'].iloc[-1] == 'down'):\n",
    "            if len(positions) > 0:\n",
    "                for j in range(len(positions)):\n",
    "                    if positions[j].symbol == symbol:                   \n",
    "                        # Order type is a buy\n",
    "                        if positions[j].type == 0:\n",
    "                            # SF.close_all_trades(symbol, positions)\n",
    "                            SF.close_all_trades_01(symbol, positions, type=0)\n",
    "                            print(f'Symbol {symbol} closed at Profit')\n",
    "                            \n",
    "        elif (get['cci_M30'].iloc[-1] == 'up') and (get['cci_H4'].iloc[-1] == 'up'):\n",
    "            if len(positions) > 0:\n",
    "                for j in range(len(positions)):\n",
    "                    if positions[j].symbol == symbol:                   \n",
    "                        # Order type is a sell    \n",
    "                        if positions[j].type == 1:\n",
    "                            # SF.close_all_trades(symbol, positions)\n",
    "                            SF.close_all_trades_01(symbol, positions, type=1)\n",
    "                            print(f'Symbol {symbol} closed at Profit')\n",
    "        # print(symbol)                    \n",
    "        # print(get['cci_M30'].iloc[-1])\n",
    "        # print(get['cci_H4'].iloc[-1])\n",
    "        # if len(positions) > 0:\n",
    "            \n",
    "        #     for j in range(len(positions)):\n",
    "                \n",
    "        #         open_time = pd.to_datetime(positions[j].time, unit='s')\n",
    "        #         current_time = pd.to_datetime(dt.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "        #         # df = SF.collect_price(pair=symbol, api='Synthetic', days=1, granularity=\"M1\")\n",
    "        #         # df = df.set_index('date')\n",
    "                \n",
    "        #         high_price = get.close[open_time:current_time].max()\n",
    "        #         low_price = get.close[open_time:current_time].min()\n",
    "                \n",
    "        #         if positions[j].symbol == symbol:                   \n",
    "        #             # Order type is a buy\n",
    "        #             if positions[j].type == 0:\n",
    "                        \n",
    "        #                 price = positions[j].price_open\n",
    "                        \n",
    "        #                 stop_loss = round(price - (multiplier_list[i] * (price / (1 + multiplier_list[i]))), 2)\n",
    "        #                 take_profit = round(price + (multiplier_list[i] * (price / (1 + multiplier_list[i]*1.2))), 2)\n",
    "                        \n",
    "        #                 if high_price > take_profit:                       \n",
    "        #                     # SF.close_single_pair(symbol, positions[j])\n",
    "        #                     SF.close_all_trades(symbol, positions)\n",
    "        #                     print(f'Symbol {symbol} closed at Profit')\n",
    "        #                 elif low_price < stop_loss:  \n",
    "        #                     SF.close_single_pair(symbol, positions[j])\n",
    "        #                     # SF.close_all_trades(symbol, positions)\n",
    "        #                     print(f'Symbol {symbol} closed at Loss')\n",
    "                            \n",
    "                            \n",
    "        #                 # elif df_01['Stoch'].iloc[-1] == 1:\n",
    "        #                 #     # SF.close_single_pair(symbol, positions[j])\n",
    "        #                 #     SF.close_all_trades(symbol, positions)\n",
    "        #                 #     print(f'Symbol {symbol} closed at Edge')\n",
    "                            \n",
    "                            \n",
    "        #             # Order type is a sell    \n",
    "        #             elif positions[j].type == 1:\n",
    "                        \n",
    "        #                 price = positions[j].price_open\n",
    "                        \n",
    "        #                 stop_loss = round(price + (multiplier_list[i] * (price / (1 + multiplier_list[i]))), 2)\n",
    "        #                 take_profit = round(price - (multiplier_list[i] * (price / (1 + multiplier_list[i]*1.2))), 2)\n",
    "                        \n",
    "        #                 if low_price < take_profit:                       \n",
    "        #                     # SF.close_single_pair(symbol, positions[j])\n",
    "        #                     SF.close_all_trades(symbol, positions)\n",
    "        #                     print(f'Symbol {symbol} closed at Profit')\n",
    "        \n",
    "        #                 elif high_price > stop_loss:  \n",
    "        #                     SF.close_single_pair(symbol, positions[j])\n",
    "        #                     # SF.close_all_trades(symbol, positions)\n",
    "        #                     print(f'Symbol {symbol} closed at Loss')\n",
    "                            \n",
    "                        # elif df_01['Stoch'].iloc[-1] == 2:\n",
    "                        #     # SF.close_single_pair(symbol, positions[j])\n",
    "                        #     SF.close_all_trades(symbol, positions)\n",
    "                        #     print(f'Symbol {symbol} closed at Edge')\n",
    "        # print(get['Final_signal'].iloc[-1])\n",
    "    time.sleep(60)  # Wait before checking the next trade\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mt5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Shutdown MT5 connection\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m mt5\u001b[38;5;241m.\u001b[39mshutdown()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mt5' is not defined"
     ]
    }
   ],
   "source": [
    "# Shutdown MT5 connection\n",
    "mt5.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
